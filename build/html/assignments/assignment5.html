

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>作业 5 &mdash; AI-BioCourse v0.1.0 文档</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=f17d22cc"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../_static/copybutton.js?v=f281be69"></script>
      <script src="../_static/translations.js?v=beaddf03"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
    <link rel="prev" title="作业 4" href="assignment4.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            AI-BioCourse
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="搜索文档" aria-label="搜索文档" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="导航菜单">
              <p class="caption" role="heading"><span class="caption-text">目录</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../introduction.html">课程介绍</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../assignment.html">课程作业</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="assignment1.html">作业 1</a></li>
<li class="toctree-l2"><a class="reference internal" href="assignment2.html">作业 2</a></li>
<li class="toctree-l2"><a class="reference internal" href="assignment3.html">作业 3</a></li>
<li class="toctree-l2"><a class="reference internal" href="assignment4.html">作业 4</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">作业 5</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id2">数据文件</a></li>
<li class="toctree-l3"><a class="reference internal" href="#transformer">关于 Transformer 框架的搭建</a></li>
<li class="toctree-l3"><a class="reference internal" href="#token-embedding">关于词嵌入（token embedding）</a></li>
<li class="toctree-l3"><a class="reference internal" href="#positional-embedding">关于位置嵌入（Positional embedding）</a></li>
<li class="toctree-l3"><a class="reference internal" href="#faq">FAQ</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id3">为什么我的模型框架不存在问题，但是我的训练效果非常差？</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="移动版导航菜单" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">AI-BioCourse</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="页面导航">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../assignment.html">课程作业</a></li>
      <li class="breadcrumb-item active">作业 5</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/assignments/assignment5.md.txt" rel="nofollow"> 查看页面源码</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="id1">
<h1>作业 5<a class="headerlink" href="#id1" title="Link to this heading"></a></h1>
<p>该作业的主要目的是<strong>学习如何搭建 Transformer 完成指定生物学任务</strong>。</p>
<img src="..\_static\images\q5.png" height="400px" />
<p>本次作业涉及的数据文件 <code class="docutils literal notranslate"><span class="pre">genotype_fitness_data.tsv</span></code>与<a class="reference internal" href="assignment4.html"><span class="std std-doc">作业四</span></a>相同。</p>
<section id="id2">
<h2>数据文件<a class="headerlink" href="#id2" title="Link to this heading"></a></h2>
<p>该文件中需关注的列及其含义分别如下：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">dna</span></code>：该列指示 DNA 基因型数据。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">fitness</span></code>：蛋白适合度，为本次作业的预测目标。</p></li>
</ul>
</section>
<section id="transformer">
<h2>关于 Transformer 框架的搭建<a class="headerlink" href="#transformer" title="Link to this heading"></a></h2>
<p>你可以基于 Pytorch 内置的 <code class="docutils literal notranslate"><span class="pre">TransformerEncoderLayer</span></code> 直接进行调用，注意事项请参考作业 PPT。</p>
<p>你也可以基于 Pytorch 自行搭建相关的类实现 Transformer 框架，该部分可参考对分易中提供的代码示例以及网上资料。部分可以帮助理解注意力机制和 Transformer 搭建的资料如下：</p>
<ul class="simple">
<li><p><a class="reference external" href="https://zh-v2.d2l.ai/chapter_attention-mechanisms/index.html">动手学深度学习 —— 注意力机制</a></p></li>
<li><p><a class="reference external" href="https://github.com/ImagineAILab/ai-by-hand-excel/blob/main/advanced/Self-Attention.xlsx">Excel 可视化注意力机制运算</a></p></li>
</ul>
</section>
<section id="token-embedding">
<h2>关于词嵌入（token embedding）<a class="headerlink" href="#token-embedding" title="Link to this heading"></a></h2>
<p>词嵌入中，你可以将 DNA 序列按照先前的格式转换为串联的独热编码，然后对其<strong>进行形状转换</strong>并<strong>通过一个形状为 (4, embedding_dim) 的全连接层</strong>（<code class="docutils literal notranslate"><span class="pre">nn.Linear</span></code>）计算每个 token 的 embedding：</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 独热编码转换的示例</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">torch</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X_one_hot</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X_one_hot</span><span class="o">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">])</span> <span class="c1"># 形状为 (batch_size, concatenated_one_hot_encoding)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X_one_hot</span> <span class="o">=</span> <span class="n">X_one_hot</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span> <span class="c1"># 形状为 (batch_size, sequence_len, one_hot_encoding)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X_one_hot</span>
<span class="n">tensor</span><span class="p">([[[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span> <span class="c1"># 形状为 (one_hot_encoding, embedding_dim)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">embedding</span> <span class="o">=</span> <span class="n">linear</span><span class="p">(</span><span class="n">X_one_hot</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">embedding</span><span class="o">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span> <span class="c1"># 形状为 (batch_size, sequence_len, embedding_dim)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">embedding</span>
<span class="n">tensor</span><span class="p">([[[</span><span class="o">-</span><span class="mf">0.5414</span><span class="p">,</span>  <span class="mf">0.4139</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2857</span><span class="p">,</span>  <span class="mf">0.3318</span><span class="p">,</span>  <span class="mf">0.4266</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0915</span><span class="p">,</span>  <span class="mf">0.3114</span><span class="p">,</span>
          <span class="o">-</span><span class="mf">0.4350</span><span class="p">,</span>  <span class="mf">0.0161</span><span class="p">,</span>  <span class="mf">0.3460</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">0.0621</span><span class="p">,</span>  <span class="mf">0.1637</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0687</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1976</span><span class="p">,</span>  <span class="mf">0.1287</span><span class="p">,</span>  <span class="mf">0.2911</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2988</span><span class="p">,</span>
          <span class="o">-</span><span class="mf">0.3576</span><span class="p">,</span>  <span class="mf">0.1104</span><span class="p">,</span>  <span class="mf">0.4234</span><span class="p">]]],</span> <span class="n">grad_fn</span><span class="o">=&lt;</span><span class="n">ViewBackward0</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
<p>该示例仅供理解独热编码转换到词嵌入过程中张量形状的变化，请参考上述运算过程自行搭建一个类以实现独热编码到词嵌入的转换。</p>
<p>你也可以选择传入 token 的索引，通过 <code class="docutils literal notranslate"><span class="pre">nn.Embedding</span></code> 计算其 embedding：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_token_idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span> <span class="c1"># 假设 0，1，2，3 分别代表四个不同的碱基（此处的数字即代表碱基的 &#39;索引&#39;）</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_token_idx</span><span class="o">.</span><span class="n">shape</span>
<span class="go">torch.Size([1, 5]) # 形状为 (batch_size, sequence_len)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">emb</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span> <span class="c1"># 形状为 (num_of_token_idx, embedding_dim)，num_of_token_idx 即索引的总数量，此处仅四种碱基因此为 4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">embedding</span> <span class="o">=</span> <span class="n">emb</span><span class="p">(</span><span class="n">X_token_idx</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">embedding</span><span class="o">.</span><span class="n">shape</span>
<span class="go">torch.Size([1, 5, 10]) # 形状为 (batch_size, sequence_len, embedding_dim)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">embedding</span>
<span class="go">tensor([[[-0.2933, -1.1887, -0.3512, -1.7246, -0.6260, -1.7295, -0.9526,</span>
<span class="go">           0.6080, -1.2085, -1.6522],</span>
<span class="go">         [-0.8493,  1.2595,  0.6788,  0.5044, -0.2911,  1.2267, -1.5274,</span>
<span class="go">           1.1209,  0.0558, -0.1310],</span>
<span class="go">         [-0.0354,  1.0134,  1.0404,  0.0980,  0.3095,  0.9719, -2.3796,</span>
<span class="go">           1.2440, -0.3585, -0.8697],</span>
<span class="go">         [-0.4226,  0.9418, -0.7537,  1.8708,  0.7265, -0.6792,  0.5071,</span>
<span class="go">          -1.0920, -0.0810, -2.5961],</span>
<span class="go">         [-0.8493,  1.2595,  0.6788,  0.5044, -0.2911,  1.2267, -1.5274,</span>
<span class="go">           1.1209,  0.0558, -0.1310]]], grad_fn=&lt;EmbeddingBackward0&gt;)</span>
</pre></div>
</div>
<p>独热编码到 embedding 的图示理解：</p>
<img src="..\_static\images\q5_onehot2embedding.png" height="300px" />
<p>token 索引到 embedding 的图示理解：</p>
<img src="..\_static\images\q5_embeddinglayer.png" height="300px" />
<p>两种 embedding 计算方式本质上是相同的。</p>
</section>
<section id="positional-embedding">
<h2>关于位置嵌入（Positional embedding）<a class="headerlink" href="#positional-embedding" title="Link to this heading"></a></h2>
<p>位置嵌入中，你可以参考 Transformer 原架构中提出的计算方法，通过正弦和余弦函数计算每个位置上的位置编码（这种情况下，位置编码是固定的）。</p>
<p>此外，你也可以使用 <code class="docutils literal notranslate"><span class="pre">nn.Parameter</span></code> 创建一个与序列长度等长的可学习参数作为每个位置上的位置编码（这种情况下，位置编码是可学习的）。</p>
</section>
<section id="faq">
<h2>FAQ<a class="headerlink" href="#faq" title="Link to this heading"></a></h2>
<section id="id3">
<h3>为什么我的模型框架不存在问题，但是我的训练效果非常差？<a class="headerlink" href="#id3" title="Link to this heading"></a></h3>
<p>作为参考，本次作业最终能达到的 Pearson R 应当在 0.8 以上。如果最终你的模型性能未达到该水平，则可检查是否存在以下问题：</p>
<ul class="simple">
<li><p>模型的架构过于复杂导致训练缓慢及性能提升不明显，该作业中模型不需要过于复杂，你可以尝试使用更低的 Attention Block 数量及 embedding 维度。</p></li>
<li><p>在训练前期使用了早停策略，使模型的训练过快地被终止。该作业中模型可能需要经过较多 epoch 才能得到性能提升，在训练前期可能会经历震荡而过早触发早停。这种情况下可以尝试延长早停的触发时间或者尝试直接设定一个较高的 epoch 数进行训练。</p></li>
</ul>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="页脚">
        <a href="assignment4.html" class="btn btn-neutral float-left" title="作业 4" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> 上一页</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; 版权所有 2024, SYSU。</p>
  </div>

  利用 <a href="https://www.sphinx-doc.org/">Sphinx</a> 构建，使用的 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">主题</a>
    由 <a href="https://readthedocs.org">Read the Docs</a> 开发.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>